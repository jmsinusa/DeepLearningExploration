{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO tutorial: Coding YOLO v3\n",
    "https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/\n",
    "\n",
    "This documents describes the code that I wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util' from '/src/PyTorch/Example_implementation_yolo_tutorial/util.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import darknet\n",
    "import util\n",
    "\n",
    "import importlib     # During dev only\n",
    "importlib.reload(darknet)  # During dev only\n",
    "importlib.reload(util) # During dev only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the 'official' config file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function `darknet.parse_cfg`.\n",
    "\n",
    "The idea here is to parse the cfg, and store every block as a dict. The attributes of the blocks and their values are stored as key-value pairs in the dictionary. As we parse through the cfg, we keep appending these dicts, denoted by the variable block in our code, to a list blocks. Our function will return this block.\n",
    "\n",
    "We begin by saving the content of the cfg file in a list of strings. The following code performs some preprocessing on this list.\n",
    "\n",
    "    file = open(cfgfile, 'r')\n",
    "    lines = file.read().split('\\n')                        # store the lines in a list\n",
    "    lines = [x for x in lines if len(x) > 0]               # get read of the empty lines \n",
    "    lines = [x for x in lines if x[0] != '#']              # get rid of comments\n",
    "    lines = [x.rstrip().lstrip() for x in lines]           # get rid of fringe whitespaces\n",
    "    \n",
    "Now loop over the resultant to get blocks\n",
    "\n",
    "    block = {}\n",
    "    blocks = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line[0] == \"[\":               # This marks the start of a new block\n",
    "            if len(block) != 0:          # If block is not empty, implies it is storing values of previous block.\n",
    "                blocks.append(block)     # add it the blocks list\n",
    "                block = {}               # re-init the block\n",
    "            block[\"type\"] = line[1:-1].rstrip()     \n",
    "        else:\n",
    "            key,value = line.split(\"=\") \n",
    "            block[key.rstrip()] = value.lstrip()\n",
    "    blocks.append(block)\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Takes a configuration file\n",
      "\n",
      "    Returns a list of blocks. Each blocks describes a block in the neural\n",
      "    network to be built. Block is represented as a dictionary in the list\n",
      "    \n",
      "{'type': 'net', 'batch': '64', 'subdivisions': '16', 'width': '608', 'height': '608', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'yolo', 'mask': '6,7,8', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.7', 'truth_thresh': '1', 'random': '1'}\n",
      "\n",
      "{'type': 'route', 'layers': '-4'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'upsample', 'stride': '2'}\n",
      "\n",
      "{'type': 'route', 'layers': '-1, 61'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'yolo', 'mask': '3,4,5', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.7', 'truth_thresh': '1', 'random': '1'}\n",
      "\n",
      "{'type': 'route', 'layers': '-4'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'upsample', 'stride': '2'}\n",
      "\n",
      "{'type': 'route', 'layers': '-1, 36'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}\n",
      "\n",
      "{'type': 'convolutional', 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}\n",
      "\n",
      "{'type': 'yolo', 'mask': '0,1,2', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.7', 'truth_thresh': '1', 'random': '1'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(darknet.parse_cfg.__doc__)\n",
    "blocks = darknet.parse_cfg('cfg/yolov3.cfg')\n",
    "for cc in blocks:\n",
    "    print(cc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the building blocks\n",
    "Now we are going to use the list returned by the above parse_cfg to construct PyTorch modules for the blocks present in the config file.\n",
    "\n",
    "We have 5 types of layers in the list (mentioned above). PyTorch provides pre-built layers for types convolutional and upsample. We will have to write our own modules for the rest of the layers by extending the `nn.Module class`.\n",
    "\n",
    "Create a function **darknet.create_modules(blocks)**\n",
    "\n",
    "#### nn.ModuleList\n",
    "Our function will return a nn.ModuleList. This class is almost like a normal list containing nn.Module objects. However, when we add nn.ModuleList as a member of a nn.Module object (i.e. when we add modules to our network), all the parameters of nn.Module objects (modules) inside the nn.ModuleList are added as parameters of the nn.Module object (i.e. our network, which we are adding the nn.ModuleList as a member of) as well.\n",
    "\n",
    "#### prev_filter\n",
    "We need to keep track of number of filters in the layer on which the convolutional layer is being applied. We use the variable `prev_filter` to do this. We initialise this to 3, as the image has 3 filters corresponding to the RGB channels.\n",
    "\n",
    "#### output_filters\n",
    "The route layer brings (possibly concatenated) feature maps from previous layers. If there's a convolutional layer right in front of a route layer, then the kernel is applied on the feature maps of previous layers, precisely the ones the route layer brings. Therefore, we need to keep a track of the number of filters in not only the previous layer, but each one of the preceding layers. As we iterate, we append the number of output filters of each block to the list output_filters.\n",
    "\n",
    "    net_info = blocks[0]     # Captures the information about the input and pre-processing\n",
    "    module_list = nn.ModuleList()\n",
    "    prev_filters = 3\n",
    "    output_filters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Take in a list of blocks (the first is the net info) and output PyTorch model.\n",
      "    return (net_info, module_list)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(darknet.create_modules.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over the list of blocks, and create a PyTorch module for each block as we go.\n",
    "\n",
    "#### nn.Sequential\n",
    "`nn.Sequential` class is used to sequentially execute a number of nn.Module objects. If you look at the cfg, you will realize a block may contain more than one layer. For example, a block of type convolutional has a batch norm layer as well as leaky ReLU activation layer in addition to a convolutional layer. We string together these layers using the nn.Sequential and the add_module function.\n",
    "\n",
    "    for index, x in enumerate(blocks[1:]):\n",
    "        module = nn.Sequential()\n",
    "\n",
    "        #check the type of block\n",
    "        #create a new module for the block\n",
    "        #append to module_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution layers\n",
    "    if (x[\"type\"] == \"convolutional\"):\n",
    "            #Get the info about the layer\n",
    "            activation = x[\"activation\"]\n",
    "            try:\n",
    "                batch_normalize = int(x[\"batch_normalize\"])\n",
    "                bias = False\n",
    "            except:\n",
    "                batch_normalize = 0\n",
    "                bias = True\n",
    "\n",
    "            filters= int(x[\"filters\"])\n",
    "            padding = int(x[\"pad\"])\n",
    "            kernel_size = int(x[\"size\"])\n",
    "            stride = int(x[\"stride\"])\n",
    "\n",
    "            if padding:\n",
    "                pad = (kernel_size - 1) // 2\n",
    "            else:\n",
    "                pad = 0\n",
    "\n",
    "            #Add the convolutional layer\n",
    "            conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias = bias)\n",
    "            module.add_module(\"conv_{0}\".format(index), conv)\n",
    "\n",
    "            #Add the Batch Norm Layer\n",
    "            if batch_normalize:\n",
    "                bn = nn.BatchNorm2d(filters)\n",
    "                module.add_module(\"batch_norm_{0}\".format(index), bn)\n",
    "\n",
    "            #Check the activation. \n",
    "            #It is either Linear or a Leaky ReLU for YOLO\n",
    "            if activation == \"leaky\":\n",
    "                activn = nn.LeakyReLU(0.1, inplace = True)\n",
    "                module.add_module(\"leaky_{0}\".format(index), activn)\n",
    "\n",
    "#### Upsampling layers\n",
    "        #If it's an upsampling layer\n",
    "        #We use Bilinear2dUpsampling\n",
    "        elif (x[\"type\"] == \"upsample\"):\n",
    "            stride = int(x[\"stride\"])\n",
    "            upsample = nn.Upsample(scale_factor = 2, mode = \"bilinear\")\n",
    "            module.add_module(\"upsample_{}\".format(index), upsample)\n",
    "            \n",
    "#### Route layer\n",
    "\n",
    "The Route Layer, just like any other layer performs an operation (bringing forward previous layer / concatenation). In PyTorch, when we define a new layer, we subclass `nn.Module` and write the operation the layer performs in the forward function of the nn.Module object.\n",
    "\n",
    "For designing a layer for the Route block, we will have to build a `nn.Module` object that is initialized with values of the attribute layers as it's member(s). Then, we can write the code to concatenate/bring forward the feature maps in the forward function. Finally, we then execute this layer in th `forward` function of our network.\n",
    "\n",
    "But given the code of concatenation is fairly short and simple (calling torch.cat on feature maps), designing a layer as above will lead to unnecessary abstraction that just increases boiler plate code. Instead, what we can do is put a dummy layer in place of a proposed route layer, and then perform the concatenation directly in the forward function of the nn.Module object representing darknet.\n",
    "\n",
    "The convolutional layer just in front of a route layer applies it's kernel to (possibly concatenated) feature maps from a previous layers. The following code updates the filters variable to hold the number of filters outputted by a route layer.\n",
    "\n",
    "    if end < 0:\n",
    "        #If we are concatenating maps\n",
    "        filters = output_filters[index + start] + output_filters[index + end]\n",
    "    else:\n",
    "        filters= output_filters[index + start]\n",
    "\n",
    "\n",
    "###### EmptyLayer\n",
    "\n",
    "    class EmptyLayer(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(EmptyLayer, self).__init__()\n",
    "\n",
    "###### Route Layer code\n",
    "\n",
    "        #If it is a route layer\n",
    "        elif (x[\"type\"] == \"route\"):\n",
    "            x[\"layers\"] = x[\"layers\"].split(',')\n",
    "            #Start  of a route\n",
    "            start = int(x[\"layers\"][0])\n",
    "            #end, if there exists one.\n",
    "            try:\n",
    "                end = int(x[\"layers\"][1])\n",
    "            except:\n",
    "                end = 0\n",
    "            #Positive anotation\n",
    "            if start > 0: \n",
    "                start = start - index\n",
    "            if end > 0:\n",
    "                end = end - index\n",
    "            route = EmptyLayer()\n",
    "            module.add_module(\"route_{0}\".format(index), route)\n",
    "            if end < 0:\n",
    "                filters = output_filters[index + start] + output_filters[index + end]\n",
    "            else:\n",
    "                filters= output_filters[index + start]\n",
    "\n",
    "#### Shortcut layer\n",
    "\n",
    "        #shortcut corresponds to skip connection\n",
    "        elif x[\"type\"] == \"shortcut\":\n",
    "            shortcut = EmptyLayer()\n",
    "            module.add_module(\"shortcut_{}\".format(index), shortcut)\n",
    "            \n",
    "#### YOLO layer (detection)\n",
    "\n",
    "        #Yolo is the detection layer\n",
    "        elif x[\"type\"] == \"yolo\":\n",
    "            mask = x[\"mask\"].split(\",\")\n",
    "            mask = [int(x) for x in mask]\n",
    "\n",
    "            anchors = x[\"anchors\"].split(\",\")\n",
    "            anchors = [int(a) for a in anchors]\n",
    "            anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors),2)]\n",
    "            anchors = [anchors[i] for i in mask]\n",
    "\n",
    "            detection = DetectionLayer(anchors)\n",
    "            module.add_module(\"Detection_{}\".format(index), detection)\n",
    "\n",
    "###### DetectionLayer()\n",
    "We define a new layer DetectionLayer that holds the anchors used to detect bounding boxes.\n",
    "\n",
    "    class DetectionLayer(nn.Module):\n",
    "        def __init__(self, anchors):\n",
    "            super(DetectionLayer, self).__init__()\n",
    "            self.anchors = anchors\n",
    "            \n",
    "The whole function returns:\n",
    "\n",
    "    return (net_info, module_list)\n",
    "    \n",
    "### Test darknet.create_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET_INFO:\n",
      "type : net\n",
      "batch : 64\n",
      "subdivisions : 16\n",
      "width : 608\n",
      "height : 608\n",
      "channels : 3\n",
      "momentum : 0.9\n",
      "decay : 0.0005\n",
      "angle : 0\n",
      "saturation : 1.5\n",
      "exposure : 1.5\n",
      "hue : .1\n",
      "learning_rate : 0.001\n",
      "burn_in : 1000\n",
      "max_batches : 500200\n",
      "policy : steps\n",
      "steps : 400000,450000\n",
      "scales : .1,.1\n",
      "\n",
      "MODULE LIST\n",
      "Sequential(\n",
      "  (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_0): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_1): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_2): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_3): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_4): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_5): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_6): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_7): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_8): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_9): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_10): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_11): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_12): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_13): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_14): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_15): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_16): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_17): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_18): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_19): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_20): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_21): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_22): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_23): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_24): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_25): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_26): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_27): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_28): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_29): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_30): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_31): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_32): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_33): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_34): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_35): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_36): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_37): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_38): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_39): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_40): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_41): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_42): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_43): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_44): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_45): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_46): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_47): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_48): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_49): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_50): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_51): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_52): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_53): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_54): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_55): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_56): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_57): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_58): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_59): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_60): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_61): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_62): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_63): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_64): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_65): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_66): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_67): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_68): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_69): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_70): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_71): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_72): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_73): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (shortcut_74): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_75): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_76): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_77): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_78): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_79): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_80): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Sequential(\n",
      "  (Detection_82): DetectionLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (route_83): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_84): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (upsample_85): Upsample(scale_factor=2, mode=bilinear)\n",
      ")\n",
      "Sequential(\n",
      "  (route_86): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_87): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_88): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_89): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_90): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_91): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_92): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Sequential(\n",
      "  (Detection_94): DetectionLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (route_95): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_96): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (upsample_97): Upsample(scale_factor=2, mode=bilinear)\n",
      ")\n",
      "Sequential(\n",
      "  (route_98): EmptyLayer()\n",
      ")\n",
      "Sequential(\n",
      "  (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_99): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_100): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_101): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_102): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_103): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_104): LeakyReLU(negative_slope=0.1, inplace)\n",
      ")\n",
      "Sequential(\n",
      "  (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Sequential(\n",
      "  (Detection_106): DetectionLayer()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(darknet)  # During dev only\n",
    "net_info, module_list = darknet.create_modules(blocks)\n",
    "print(\"NET_INFO:\")\n",
    "for key in net_info:\n",
    "    print(key, \":\", net_info[key])\n",
    "print()\n",
    "print(\"MODULE LIST\")\n",
    "for mod in module_list:\n",
    "    print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the network\n",
    "Now we must define our network, using the `create_modules` function above.\n",
    "\n",
    "    class Darknet(nn.Module):\n",
    "        def __init__(self, cfgfile):\n",
    "            super(Darknet, self).__init__()\n",
    "            self.blocks = parse_cfg(cfgfile)\n",
    "            self.net_info, self.module_list = create_modules(self.blocks)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Class for defining our network\n",
      "    \n",
      "Number of blocks: 108\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(darknet)  # During dev only\n",
    "dark = darknet.Darknet('cfg/yolov3.cfg')\n",
    "print(dark.__doc__)\n",
    "print('Number of blocks:', len(dark.blocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the forward pass of the network\n",
    "The forward pass of the network is implemented by overriding the `forward` method of the `nn.Module` class.\n",
    "\n",
    "`forward` serves two purposes. First, to calculate the output, and second, to transform the output detection feature maps in a way that it can be processed easier (such as transforming them such that detection maps across multiple scales can be concatenated, which otherwise isn't possible as they are of different dimensions).\n",
    "\n",
    "    def forward(self, x, CUDA):\n",
    "        modules = self.blocks[1:]\n",
    "        outputs = {}   #We cache the outputs for the route layer\n",
    "        \n",
    "`forward` takes three arguments, self, the input x and CUDA, which if true, would use GPU to accelerate the forward pass.\n",
    "\n",
    "Here, we iterate over `self.blocks[1:]` instead of self.blocks since the first element of `self.blocks` is a net block which isn't a part of the forward pass.\n",
    "\n",
    "Since route and shortcut layers need output maps from previous layers, we cache the output feature maps of every layer in a dict outputs. The keys are the the indices of the layers, and the values are the feature maps.\n",
    "\n",
    "We now iterate over `module_list` which contains the modules of the network. The thing to notice here is that the modules have been appended in the same order as they are present in the configuration file. This means, we can simply run our input through each module to get our output.\n",
    "\n",
    "    write = 0     #This is explained a bit later\n",
    "    for i, module in enumerate(modules):        \n",
    "        module_type = (module[\"type\"])\n",
    "        \n",
    "Now we deal with each module by type\n",
    "\n",
    "#### Convolutional and upsample\n",
    "\n",
    "        if module_type == \"convolutional\" or module_type == \"upsample\":\n",
    "            x = self.module_list[i](x)\n",
    "            \n",
    "#### Route Layer / Shortcut Layer\n",
    "\n",
    "If you look the code for route layer, we have to account for two cases (as described in part 2). For the case in which we have to concatenate two feature maps we use the torch.cat function with the second argument as 1. This is because we want to concatenate the feature maps along the depth. (In PyTorch, input and output of a convolutional layer has the format batch x channels x H x W. The depth corresponding the the channel dimension).\n",
    "\n",
    "        elif module_type == \"route\":\n",
    "            layers = module[\"layers\"]\n",
    "            layers = [int(a) for a in layers]\n",
    "\n",
    "            if (layers[0]) > 0:\n",
    "                layers[0] = layers[0] - i\n",
    "\n",
    "            if len(layers) == 1:\n",
    "                x = outputs[i + (layers[0])]\n",
    "\n",
    "            else:\n",
    "                if (layers[1]) > 0:\n",
    "                    layers[1] = layers[1] - i\n",
    "\n",
    "                map1 = outputs[i + layers[0]]\n",
    "                map2 = outputs[i + layers[1]]\n",
    "\n",
    "                x = torch.cat((map1, map2), 1)\n",
    "\n",
    "        elif  module_type == \"shortcut\":\n",
    "            from_ = int(module[\"from\"])\n",
    "            x = outputs[i-1] + outputs[i+from_]\n",
    "\n",
    "#### YOLO (detection) layer\n",
    "\n",
    "The output of YOLO is a convolutional feature map that contains the bounding box attributes along the depth of the feature map. The attributes bounding boxes predicted by a cell are stacked one by one along each other. So, if you have to access the second bounding of cell at (5,6), then you will have to index it by `map[5,6, (5+C): 2*(5+C)]`. This form is very inconvenient for output processing such as thresholding by a object confidence, adding grid offsets to centers, applying anchors etc.\n",
    "\n",
    "Another problem is that since detections happen at three scales, the dimensions of the prediction maps will be different. Although the dimensions of the three feature maps are different, the output processing operations to be done on them are similar. It would be nice to have to do these operations on a single tensor, rather than three separate tensors.\n",
    "\n",
    "To remedy these problems, we introduce the function `predict_transform`\n",
    "\n",
    "### predict_transform\n",
    "\n",
    "The function `predict_transform` lives in the file util.py and we will import the function when we use it in forward of Darknet class.\n",
    "\n",
    "predict_transform takes in 5 parameters; prediction (our output), inp_dim (input image dimension), anchors, num_classes, and an optional CUDA flag\n",
    "\n",
    "    def predict_transform(prediction, inp_dim, anchors, num_classes, CUDA = True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Transform predictions\n",
      "    :param prediction: output from forward pass of model\n",
      "    :param inp_dim: image input dimensions\n",
      "    :param anchors:\n",
      "    :param num_classes:\n",
      "    :param CUDA: True if GPU\n",
      "    :return:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "importlib.reload(util)\n",
    "print(util.predict_transform.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict_transform` function takes an detection feature map and turns it into a 2-D tensor, where each row of the tensor corresponds to attributes of a bounding box, in the following order:\n",
    "\n",
    "- 1st bounding box at (0,0)\n",
    "- 2nd box at (0,0)\n",
    "- 3rd box at (0,0)\n",
    "- 1st box at (0,1)\n",
    "\n",
    "Code:\n",
    "\n",
    "    batch_size = prediction.size(0)\n",
    "    stride =  inp_dim // prediction.size(2)\n",
    "    grid_size = inp_dim // stride\n",
    "    bbox_attrs = 5 + num_classes\n",
    "    num_anchors = len(anchors)\n",
    "    \n",
    "    prediction = prediction.view(batch_size, bbox_attrs*num_anchors, grid_size*grid_size)\n",
    "    prediction = prediction.transpose(1,2).contiguous()\n",
    "    prediction = prediction.view(batch_size, grid_size*grid_size*num_anchors, bbox_attrs)\n",
    "    \n",
    "The dimensions of the anchors are in accordance to the height and width attributes of the net block. These attributes describe the dimensions of the input image, which is larger (by a factor of stride) than the detection map. Therefore, we must divide the anchors by the stride of the detection feature map.\n",
    "\n",
    "    anchors = [(a[0]/stride, a[1]/stride) for a in anchors]\n",
    "    \n",
    "#### Transform the output\n",
    "\n",
    "Sigmoid the x,y coordinates and the objectness score.\n",
    "\n",
    "    #Sigmoid the  centre_X, centre_Y. and object confidencce\n",
    "    prediction[:,:,0] = torch.sigmoid(prediction[:,:,0])\n",
    "    prediction[:,:,1] = torch.sigmoid(prediction[:,:,1])\n",
    "    prediction[:,:,4] = torch.sigmoid(prediction[:,:,4])\n",
    "\n",
    "Add the grid offsets to the center cordinates prediction.\n",
    "\n",
    "    #Add the center offsets\n",
    "    grid = np.arange(grid_size)\n",
    "    a,b = np.meshgrid(grid, grid)\n",
    "\n",
    "    x_offset = torch.FloatTensor(a).view(-1,1)\n",
    "    y_offset = torch.FloatTensor(b).view(-1,1)\n",
    "\n",
    "    if CUDA:\n",
    "        x_offset = x_offset.cuda()\n",
    "        y_offset = y_offset.cuda()\n",
    "\n",
    "    x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1,num_anchors).view(-1,2).unsqueeze(0)\n",
    "\n",
    "    prediction[:,:,:2] += x_y_offset\n",
    "    \n",
    "Apply the anchors to the dimensions of the bounding box.\n",
    "\n",
    "    #log space transform height and the width\n",
    "    anchors = torch.FloatTensor(anchors)\n",
    "\n",
    "    if CUDA:\n",
    "        anchors = anchors.cuda()\n",
    "\n",
    "    anchors = anchors.repeat(grid_size*grid_size, 1).unsqueeze(0)\n",
    "    prediction[:,:,2:4] = torch.exp(prediction[:,:,2:4])*anchors\n",
    "\n",
    "Apply sigmoid activation to the the class scores\n",
    "\n",
    "    prediction[:,:,5: 5 + num_classes] = torch.sigmoid((prediction[:,:, 5 : 5 + num_classes]))\n",
    "    \n",
    "The last thing we want to do here, is to resize the detections map to the size of the input image. The bounding box attributes here are sized according to the feature map (say, 13 x 13). If the input image was 416 x 416, we multiply the attributes by 32, or the stride variable.\n",
    "\n",
    "    prediction[:,:,:4] *= stride\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection layer... again\n",
    "\n",
    "Now that we have transformed our output tensors, we can now concatenate the detection maps at three different scales into one big tensor. Notice this was not possible prior to our transformation, as one cannot concatenate feature maps having different spatial dimensions.\n",
    "\n",
    "#### YOLO (detection) layer... again\n",
    "\n",
    "        elif module_type == 'yolo':        \n",
    "\n",
    "            anchors = self.module_list[i][0].anchors\n",
    "            #Get the input dimensions\n",
    "            inp_dim = int (self.net_info[\"height\"])\n",
    "\n",
    "            #Get the number of classes\n",
    "            num_classes = int (module[\"classes\"])\n",
    "\n",
    "            #Transform \n",
    "            x = x.data\n",
    "            x = predict_transform(x, inp_dim, anchors, num_classes, CUDA)\n",
    "            if not write:              #if no collector has been intialised. \n",
    "                detections = x\n",
    "                write = 1\n",
    "\n",
    "            else:       \n",
    "                detections = torch.cat((detections, x), 1)\n",
    "\n",
    "        outputs[i] = x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test forward pass of network\n",
    "\n",
    "Two solutions: First using the recommended code (cv2), second trying to do this in numpy / pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
